{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_final_asignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfwbMB6hUhaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.nn import MaxPool1d\n",
        "from torch.nn.functional import relu\n",
        "\n",
        "# Set random seed=2003\n",
        "SEED = 2003\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', batch_first = True,fix_length=50,stop_words='en')\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "fields = [('PhraseId',None),('SentimentId',None),('Phrase',TEXT),('Sentiment',LABEL)]\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "training_data=data.TabularDataset( '/content/drive/My Drive/Colab Notebooks/train.tsv', format = 'tsv',fields =fields,skip_header = True)\n",
        "\n",
        "# Split the dataset into training and testinng sets\n",
        "train_data, test_data = training_data.split(split_ratio=0.3, random_state = random.seed(SEED))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "af1c4a68-729b-45c8-bb8d-7526fc5e010e",
        "id": "Ts-dy4jNWE96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "next(iter(training_data))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.data.example.Example at 0x7fc0ef316240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zftw7vmrWHgi",
        "colab_type": "code",
        "outputId": "5e186f89-a5a5-43d5-819a-a7431d5fc21d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/train.tsv\", sep='\\t')\n",
        "df.iloc[0:5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muxkx1TMXQdD",
        "colab_type": "code",
        "outputId": "d0f92f82-1ae3-4961-e7fe-003fd5166d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "df['Sentiment'].value_counts()\n",
        "ax = pd.value_counts(df['Sentiment']).plot(kind=\"bar\",title = 'Sentiment Distribution')\n",
        "ax.set_xlabel(\"Sentiment\")\n",
        "ax.set_ylabel(\"Frequency\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAETCAYAAAD3WTuEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nliISERGN/X/f5Onohwn+MQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9bf1010a-c0db-4975-8757-56f63c07492f",
        "id": "8r0b5t5fV_Mx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount with the google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HIfw4A4xtwre",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dddb34b3-0b6c-415d-c550-7a0d3e12904a"
      },
      "source": [
        "#initialize glove embeddings and build vocabulary\n",
        "TEXT.build_vocab(train_data,test_data,min_freq=3,vectors = \"glove.6B.100d\")  \n",
        "MAX_VOCAB_SIZE = 10_000\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:28, 2.22MB/s]                          \n",
            "100%|█████████▉| 399169/400000 [00:23<00:00, 17392.76it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0ae9c5de-7521-415f-cb77-b9ebc17e38e5",
        "id": "M4lqZzG7tvNo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#No. of unique tokens in text\n",
        "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
        "\n",
        "#No. of unique tokens in label\n",
        "print(\"Size of LABEL vocabulary:\",LABEL.vocab.itos)\n",
        "\n",
        "#Commonly used words\n",
        "print(TEXT.vocab.freqs.most_common(10))    "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of TEXT vocabulary: 16768\n",
            "Size of LABEL vocabulary: ['2', '3', '1', '4', '0']\n",
            "[('the', 46965), (',', 42006), ('a', 33635), ('of', 32639), ('and', 32066), ('-', 23075), ('to', 22676), ('.', 17688), (\"'s\", 16971), ('in', 13775)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3EKFmy9Xtu7m",
        "colab": {}
      },
      "source": [
        "# define the batch size\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Create PyTorch iterators to use in training/testing\n",
        "train_iterator = data.BucketIterator(\n",
        "    train_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)\n",
        "test_iterator=data.BucketIterator(\n",
        "    test_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFxKwhDHgU0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class CNN_Text(nn.Module):\n",
        "    ''' Define network architecture and forward path. '''\n",
        "    def __init__(self, vocab_size, \n",
        "                 vector_size, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        # Create word embeddings from the input words     \n",
        "        self.embedding = nn.Embedding(vocab_size, vector_size, \n",
        "                                      padding_idx = pad_idx)\n",
        "\n",
        "        self.conv= nn.Conv1d(50,100,3,stride=2)\n",
        "\n",
        "        self.conv2= nn.Conv1d(100,150,4,stride=1) \n",
        "\n",
        "        self.conv3= nn.Conv1d(150,200,4,stride=1) \n",
        "\n",
        "        self.conv4= nn.Conv1d(200,250,4,stride=1) \n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear = nn.Linear(10000, 4096)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(num_features=4096)\n",
        "\n",
        "        self.linear2 = nn.Linear(4096,output_dim)        \n",
        "        \n",
        "    def forward(self, text):\n",
        "        '''Forward path of the network.'''       \n",
        "        # Get word embeddings and formt them for convolutions\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        x = relu(self.conv(embedded))        \n",
        "        \n",
        "        x = relu(self.conv2(x))\n",
        "\n",
        "        x = relu(self.conv3(x))\n",
        "\n",
        "        x = relu(self.conv4(x))\n",
        "\n",
        "        x = self.flatten(x)\n",
        "  \n",
        "        x= relu(self.linear(x))\n",
        "\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCx5wh9agYE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Input Dimention\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "\n",
        "# Vector size (lower-dimensional repr. of each word)\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "# Output of the linear layer (prob of a negative review)\n",
        "OUTPUT_DIM = 5\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDRD7opJiujZ",
        "colab_type": "code",
        "outputId": "e24d0058-8fa4-4400-9b74-802364af2c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Zero the initial weights of the UNKnown and padding tokens.\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "# The string token used as padding. Default: “<pad>”.\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = CNN_Text(INPUT_DIM, EMBEDDING_DIM, \n",
        "            OUTPUT_DIM, 0.5, PAD_IDX)\n",
        "\n",
        "model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
        "\n",
        "# Set weights for unknown tokens as zeors\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model = model.to(device)\n",
        "model"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_Text(\n",
              "  (embedding): Embedding(16768, 100, padding_idx=1)\n",
              "  (conv): Conv1d(50, 100, kernel_size=(3,), stride=(2,))\n",
              "  (conv2): Conv1d(100, 150, kernel_size=(4,), stride=(1,))\n",
              "  (conv3): Conv1d(150, 200, kernel_size=(4,), stride=(1,))\n",
              "  (conv4): Conv1d(200, 250, kernel_size=(4,), stride=(1,))\n",
              "  (flatten): Flatten()\n",
              "  (linear): Linear(in_features=10000, out_features=4096, bias=True)\n",
              "  (bn1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear2): Linear(in_features=4096, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9RcbGkKz3Oi",
        "colab_type": "code",
        "outputId": "58c0b601-8246-4513-b91d-2b9f7743e423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model(next(iter(train_iterator)).Phrase).shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJTkf67onTrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(preds, y):\n",
        "    \"\"\" Return accuracy per batch. \"\"\"\n",
        "\n",
        "    predictions_ = preds.argmax(axis=1)\n",
        "    \n",
        "    correct = (predictions_ == y).float() \n",
        "    \n",
        "    return correct.sum() / len(correct)\n",
        "\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    '''Track training time. '''\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6-DVaTmBoth",
        "colab_type": "code",
        "outputId": "9f37db73-d315-43e0-80a6-3ad63d501c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Install libraries for accuracy measure\n",
        "!pip install pytorch-ignite\n",
        "from ignite.metrics import Accuracy,Precision, Recall"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zheq8YpGn2FO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    '''Train the model with specified data, optimizer, and loss function. '''\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    prec = Precision(average=True)\n",
        "    rec = Recall(average=True)\n",
        "    avg_rec = 0\n",
        "    avg_prec = 0\n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # Reset the gradient to not use them in multiple passes \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.Phrase).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.Sentiment.long())\n",
        "        \n",
        "        acc = accuracy(predictions, batch.Sentiment)\n",
        "        \n",
        "        rec.update([predictions,batch.Sentiment.long()])\n",
        "        tmp_rec = rec.compute()\n",
        "\n",
        "        prec.update([predictions,batch.Sentiment.long()])\n",
        "        tmp_prec = prec.compute()\n",
        "        \n",
        "        # Backprop\n",
        "        loss.backward()\n",
        "        \n",
        "        # Optimize the weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Record accuracy and loss\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        avg_prec += tmp_prec\n",
        "        avg_rec += tmp_rec\n",
        "\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), avg_prec/len(iterator), avg_rec/len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    '''Evaluate model performance. '''\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    prec = Precision(average=True)\n",
        "    rec = Recall(average=True)\n",
        "    avg_rec = 0\n",
        "    avg_prec = 0    \n",
        "    # Turm off dropout while evaluating\n",
        "    model.eval()\n",
        "    \n",
        "    # No need to backprop in eval\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.Phrase).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.Sentiment.long())\n",
        "            \n",
        "            acc = accuracy(predictions, batch.Sentiment)\n",
        "            rec.update([predictions,batch.Sentiment.long()])\n",
        "            tmp_rec = rec.compute()\n",
        "\n",
        "            prec.update([predictions,batch.Sentiment.long()])\n",
        "            tmp_prec = prec.compute()            \n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            avg_prec += tmp_prec\n",
        "            avg_rec += tmp_rec\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), avg_prec/len(iterator), avg_rec/len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj4KrsRXn57A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "# Network optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DovM8NfboLXT",
        "colab_type": "code",
        "outputId": "70f3cc06-c077-45ed-f6c8-84eb27284bbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 7\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "tr_loss = []\n",
        "tr_acc = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    # Calculate training time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Get epoch losses and accuracies \n",
        "    train_loss, train_acc, avg_prec, avg_rec = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc, avg_prec_val, avg_rec_val = evaluate(model, test_iterator, criterion)\n",
        "    \n",
        "    f1 = (2* (avg_prec*avg_rec)/(avg_prec +avg_rec))\n",
        "\n",
        "    f1_val = (2* (avg_prec_val*avg_rec_val)/(avg_prec_val +avg_rec_val))\n",
        "  \n",
        "    if(epoch%3==0):\n",
        "      print(\"Epoch \" +str(epoch)+ \":\\n\\tTrain_Loss = \" + str(train_loss)+\"\\n\\yTrain_Accuracy = \"+ str(train_acc))\n",
        "      print(\"F1: \",f1)\n",
        "\n",
        "      print(\"Epoch \" +str(epoch)+ \":\\n\\tValid_Loss = \" + str(valid_loss)+\"\\n\\yValid_Accuracy = \"+ str(valid_acc)+\"\\n\\yTest_prec = \"+ str(avg_prec_val)+\"\\n\\yTest_rec = \"+ str(avg_rec_val))\n",
        "      print(\"F1_ val: \",f1_val)\n",
        "\n",
        "#      print(f'Epoch: {epoch+1:2} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "\n",
        "    # end_time = time.time()\n",
        "    # epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    # Save training metrics\n",
        "    val_loss.append(valid_loss)\n",
        "    val_acc.append(valid_acc)\n",
        "    tr_loss.append(train_loss)\n",
        "    tr_acc.append(train_acc)\n",
        "    \n",
        "    # if valid_loss < best_valid_loss:\n",
        "    #     best_valid_loss = valid_loss\n",
        "    #     torch.save(model.state_dict(), 'CNN-model.pt')\n",
        "    \n",
        "    \n",
        "    # print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "   # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:\n",
            "\tTrain_Loss = 1.2314662680677746\n",
            "\\yTrain_Accuracy = 0.5234852193490319\n",
            "F1:  0.25976699052680896\n",
            "Epoch 0:\n",
            "\tValid_Loss = 1.1677252588985123\n",
            "\\yValid_Accuracy = 0.5373214493009532\n",
            "\\yTest_prec = 0.3825407169269799\n",
            "\\yTest_rec = 0.3449924773124782\n",
            "F1_ val:  0.36279765830751315\n",
            "Epoch 3:\n",
            "\tTrain_Loss = 0.7906399900498597\n",
            "\\yTrain_Accuracy = 0.673950054075407\n",
            "F1:  0.5543123466437495\n",
            "Epoch 3:\n",
            "\tValid_Loss = 1.01764652745746\n",
            "\\yValid_Accuracy = 0.6118190068507863\n",
            "\\yTest_prec = 0.5440417766983191\n",
            "\\yTest_rec = 0.40693288153490254\n",
            "F1_ val:  0.46560333853380265\n",
            "Epoch 6:\n",
            "\tTrain_Loss = 0.5557981295430142\n",
            "\\yTrain_Accuracy = 0.7792668154706126\n",
            "F1:  0.7197980626297368\n",
            "Epoch 6:\n",
            "\tValid_Loss = 1.2537857171531035\n",
            "\\yValid_Accuracy = 0.5885275348881694\n",
            "\\yTest_prec = 0.48907877777948666\n",
            "\\yTest_rec = 0.49645129419161443\n",
            "F1_ val:  0.4927374599633707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gQcliDNNzEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), '1117477_1Dconv_reg.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}